{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9543b09e",
   "metadata": {},
   "source": [
    "# WILDCAT Post-Fire Debris Flow Analysis - Complete Workflow\n",
    "This master notebook automates the entire WILDCAT model workflow for post-fire debris flow analysis. \n",
    "\n",
    "## Workflow Overview:\n",
    "1. **Data Preparation**: Extract MTBS bundles and organize fire data\n",
    "2. **GEE Processing**: Authenticate, upload assets, and download DEMs\n",
    "3. **Data Clipping**: Clip soil, EVT, and severity data to fire perimeters\n",
    "4. **WILDCAT Execution**: Run debris flow assessments for all fires\n",
    "5. **Visualization**: Generate probability raster maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e432a92",
   "metadata": {},
   "source": [
    "## 0. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d85a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath('..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Import our modules\n",
    "from src.wildcat_automation import WildcatAutomation\n",
    "from src.data_acquisition import MTBSExtractor, GEEDownloader\n",
    "from src.preprocessing import DataValidator, FolderOrganizer\n",
    "from src.visualization import RasterGenerator, BatchVisualizer\n",
    "\n",
    "print(\"‚úÖ All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09c7538",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a81a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration settings\n",
    "CONFIG = {\n",
    "    \"paths\": {\n",
    "        \"root_folder\": \"./data/fires\",\n",
    "        \"shared_data\": \"./data/shared\",\n",
    "        \"output_folder\": \"./outputs\",\n",
    "        \"wildcat_projects\": \"./wildcat_projects\"\n",
    "    },\n",
    "    \"processing\": {\n",
    "        \"years_to_process\": [\"2019\", \"2020\", \"2021\"],  # Example years\n",
    "        \"max_fires_per_year\": 5,  # Set to None for all fires\n",
    "        \"generate_rasters\": True\n",
    "    },\n",
    "    \"gee\": {\n",
    "        \"project_id\": \"ee-yourproject\",  # Update with your GEE project\n",
    "        \"asset_path\": \"projects/ee-yourproject/assets/fires\"\n",
    "    },\n",
    "    \"visualization\": {\n",
    "        \"probability_thresholds\": [16, 20, 24, 40],  # mm/hr\n",
    "        \"output_format\": \"GTiff\",\n",
    "        \"color_scheme\": \"viridis\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üìã Configuration loaded!\")\n",
    "print(f\"   Years to process: {CONFIG['processing']['years_to_process']}\")\n",
    "print(f\"   Output folder: {CONFIG['paths']['output_folder']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1006c3",
   "metadata": {},
   "source": [
    "## 1. Data Preparation - Extract MTBS Bundles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6ecfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 1: MTBS BUNDLE EXTRACTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize extractor\n",
    "extractor = MTBSExtractor(root_folder=CONFIG['paths']['root_folder'])\n",
    "\n",
    "# Check for zip files\n",
    "zip_count = extractor.count_zip_files(CONFIG['processing']['years_to_process'])\n",
    "print(f\"\\nüì¶ Found {zip_count} MTBS bundles to extract\")\n",
    "\n",
    "if zip_count > 0:\n",
    "    # Extract all bundles\n",
    "    print(\"\\nüîÑ Extracting MTBS bundles...\")\n",
    "    extraction_results = extractor.extract_all_bundles(\n",
    "        years=CONFIG['processing']['years_to_process']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Extraction complete!\")\n",
    "    print(f\"   Successful: {extraction_results['successful']}\")\n",
    "    print(f\"   Failed: {extraction_results['failed']}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No zip files found. Assuming data is already extracted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fc7a3f",
   "metadata": {},
   "source": [
    "## 2. Validate and Organize Fire Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e632bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: DATA VALIDATION AND ORGANIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize organizer\n",
    "organizer = FolderOrganizer(root_folder=CONFIG['paths']['root_folder'])\n",
    "\n",
    "# Get fire inventory\n",
    "fire_inventory = organizer.get_fire_inventory(CONFIG['processing']['years_to_process'])\n",
    "print(f\"\\nüî• Found {len(fire_inventory)} fires to process\")\n",
    "\n",
    "# Display sample fires\n",
    "print(\"\\nSample fires:\")\n",
    "for i, (fire_name, fire_info) in enumerate(list(fire_inventory.items())[:5]):\n",
    "    print(f\"  {i+1}. {fire_name}\")\n",
    "    print(f\"     - Perimeter: {'‚úÖ' if fire_info['has_perimeter'] else '‚ùå'}\")\n",
    "    print(f\"     - dNBR: {'‚úÖ' if fire_info['has_dnbr'] else '‚ùå'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811d6f70",
   "metadata": {},
   "source": [
    "## 3. Google Earth Engine Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b030c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: GOOGLE EARTH ENGINE PROCESSING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize GEE downloader\n",
    "gee_downloader = GEEDownloader(\n",
    "    project_id=CONFIG['gee']['project_id'],\n",
    "    asset_path=CONFIG['gee']['asset_path']\n",
    ")\n",
    "\n",
    "print(\"üåç Authenticating with Google Earth Engine...\")\n",
    "try:\n",
    "    import ee\n",
    "    ee.Initialize(project=CONFIG['gee']['project_id'])\n",
    "    print(\"‚úÖ GEE authentication successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå GEE authentication failed: {e}\")\n",
    "    print(\"   Please run: earthengine authenticate\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d4330b",
   "metadata": {},
   "source": [
    "### 3.1 Upload Fire Perimeters to GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec5ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüì§ Uploading fire perimeters to GEE...\")\n",
    "\n",
    "upload_results = gee_downloader.batch_upload_perimeters(\n",
    "    fire_inventory,\n",
    "    max_parallel=5\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Upload complete!\")\n",
    "print(f\"   Successful: {upload_results['successful']}\")\n",
    "print(f\"   Failed: {upload_results['failed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b3d40",
   "metadata": {},
   "source": [
    "### 3.2 Download DEMs for Each Fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9df1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüì• Downloading DEMs from GEE...\")\n",
    "\n",
    "dem_results = gee_downloader.batch_download_dems(\n",
    "    fire_inventory,\n",
    "    output_folder=CONFIG['paths']['root_folder'],\n",
    "    max_parallel=5\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ DEM download complete!\")\n",
    "print(f\"   Successful: {dem_results['successful']}\")\n",
    "print(f\"   Failed: {dem_results['failed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a54609b",
   "metadata": {},
   "source": [
    "## 4. Clip Shared Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0672af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 4: CLIPPING SHARED DATASETS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Paths to shared datasets\n",
    "shared_paths = {\n",
    "    'soil': os.path.join(CONFIG['paths']['shared_data'], 'soil', 'ussoils_18.shp'),\n",
    "    'evt': os.path.join(CONFIG['paths']['shared_data'], 'evt', 'LC24_EVT_250.tif'),\n",
    "    'severity_base': os.path.join(CONFIG['paths']['shared_data'], 'severity')\n",
    "}\n",
    "\n",
    "print(\"üìç Shared dataset paths:\")\n",
    "for dataset, path in shared_paths.items():\n",
    "    exists = \"‚úÖ\" if os.path.exists(path) else \"‚ùå\"\n",
    "    print(f\"   {dataset}: {exists} {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22726c32",
   "metadata": {},
   "source": [
    "## 5. Initialize WILDCAT Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7846ba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 5: WILDCAT PROJECT INITIALIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize WILDCAT automation\n",
    "wildcat_auto = WildcatAutomation(\n",
    "    root_folder=CONFIG['paths']['root_folder'],\n",
    "    output_folder=CONFIG['paths']['output_folder'],\n",
    "    shared_data_paths=shared_paths\n",
    ")\n",
    "\n",
    "# Initialize projects for all fires\n",
    "print(\"\\nüöÄ Initializing WILDCAT projects...\")\n",
    "init_results = wildcat_auto.initialize_all_projects(\n",
    "    fire_inventory,\n",
    "    project_folder=CONFIG['paths']['wildcat_projects']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Initialization complete!\")\n",
    "print(f\"   Successful: {init_results['successful']}\")\n",
    "print(f\"   Failed: {init_results['failed']}\")\n",
    "\n",
    "# Save initialization results\n",
    "with open('initialized_projects.json', 'w') as f:\n",
    "    json.dump(init_results['projects'], f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b9f31a",
   "metadata": {},
   "source": [
    "## 6. Run WILDCAT Assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75611766",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 6: WILDCAT BATCH ASSESSMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load initialized projects\n",
    "with open('initialized_projects.json', 'r') as f:\n",
    "    initialized_projects = json.load(f)\n",
    "\n",
    "print(f\"üìä Processing {len(initialized_projects)} fires...\")\n",
    "print(\"   Each fire will be:\")\n",
    "print(\"   1. Preprocessed (clip all datasets)\")\n",
    "print(\"   2. Assessed (calculate debris flow probability)\")\n",
    "print(\"   3. Exported (create shapefiles)\")\n",
    "\n",
    "# Run batch assessment\n",
    "assessment_results = wildcat_auto.run_batch_assessment(\n",
    "    initialized_projects,\n",
    "    skip_existing=True,\n",
    "    memory_threshold_gb=2\n",
    ")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nüìä ASSESSMENT SUMMARY:\")\n",
    "print(f\"   Total fires: {len(assessment_results)}\")\n",
    "print(f\"   ‚úÖ Successful: {sum(1 for r in assessment_results.values() if r['success'])}\")\n",
    "print(f\"   ‚ùå Failed: {sum(1 for r in assessment_results.values() if not r['success'])}\")\n",
    "\n",
    "# Save results\n",
    "with open('assessment_results.json', 'w') as f:\n",
    "    json.dump(assessment_results, f, indent=2, default=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fad6a1",
   "metadata": {},
   "source": [
    "## 7. Generate Probability Rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523dd81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 7: GENERATING PROBABILITY RASTERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize raster generator\n",
    "raster_gen = RasterGenerator(\n",
    "    output_folder=os.path.join(CONFIG['paths']['output_folder'], 'probability_rasters')\n",
    ")\n",
    "\n",
    "# Generate rasters for successful assessments\n",
    "successful_fires = [\n",
    "    (fire_name, project_info) \n",
    "    for fire_name, project_info in initialized_projects.items()\n",
    "    if assessment_results.get(fire_name, {}).get('success', False)\n",
    "]\n",
    "\n",
    "print(f\"\\nüé® Generating probability rasters for {len(successful_fires)} fires...\")\n",
    "\n",
    "raster_results = raster_gen.batch_generate_rasters(\n",
    "    successful_fires,\n",
    "    probability_columns=['P_16mmh', 'P_20mmh', 'P_24mmh', 'P_40mmh'],\n",
    "    resolution=30  # meters\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Raster generation complete!\")\n",
    "print(f\"   Generated: {raster_results['generated']} rasters\")\n",
    "print(f\"   Failed: {raster_results['failed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1679cd",
   "metadata": {},
   "source": [
    "## 8. Create Summary Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df06b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 8: CREATING SUMMARY VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize batch visualizer\n",
    "visualizer = BatchVisualizer(\n",
    "    output_folder=os.path.join(CONFIG['paths']['output_folder'], 'visualizations')\n",
    ")\n",
    "\n",
    "# Create composite maps\n",
    "print(\"\\nüó∫Ô∏è  Creating composite hazard maps...\")\n",
    "\n",
    "# 1. Overview map of all fires\n",
    "overview_map = visualizer.create_overview_map(\n",
    "    successful_fires,\n",
    "    title=\"Post-Fire Debris Flow Hazard Assessment\"\n",
    ")\n",
    "\n",
    "# 2. Individual fire summary sheets\n",
    "for fire_name, project_info in successful_fires[:5]:  # First 5 as examples\n",
    "    print(f\"\\n   Creating summary sheet for {fire_name}...\")\n",
    "    visualizer.create_fire_summary(\n",
    "        fire_name=fire_name,\n",
    "        project_dir=project_info['project_dir'],\n",
    "        raster_dir=os.path.join(CONFIG['paths']['output_folder'], 'probability_rasters', fire_name)\n",
    "    )\n",
    "\n",
    "print(\"\\n‚úÖ All visualizations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13353448",
   "metadata": {},
   "source": [
    "## 9. Generate Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL SUMMARY REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate statistics\n",
    "total_fires = len(fire_inventory)\n",
    "successful_assessments = sum(1 for r in assessment_results.values() if r['success'])\n",
    "total_area_km2 = sum(\n",
    "    project_info.get('area_km2', 0) \n",
    "    for project_info in initialized_projects.values()\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä PROCESSING STATISTICS:\")\n",
    "print(f\"   Total fires processed: {total_fires}\")\n",
    "print(f\"   Successful assessments: {successful_assessments}\")\n",
    "print(f\"   Success rate: {successful_assessments/total_fires*100:.1f}%\")\n",
    "print(f\"   Total area analyzed: {total_area_km2:.1f} km¬≤\")\n",
    "\n",
    "# Processing time summary\n",
    "if assessment_results:\n",
    "    processing_times = [\n",
    "        r['total_time'] \n",
    "        for r in assessment_results.values() \n",
    "        if r.get('success') and 'total_time' in r\n",
    "    ]\n",
    "    if processing_times:\n",
    "        print(f\"\\n‚è±Ô∏è  PERFORMANCE METRICS:\")\n",
    "        print(f\"   Average processing time: {sum(processing_times)/len(processing_times):.1f} seconds\")\n",
    "        print(f\"   Total processing time: {sum(processing_times)/60:.1f} minutes\")\n",
    "\n",
    "# Output summary\n",
    "print(f\"\\nüìÅ OUTPUT PRODUCTS:\")\n",
    "print(f\"   Shapefiles: {successful_assessments * 3} files (basins, segments, outlets)\")\n",
    "print(f\"   Probability rasters: {successful_assessments * 4} files (4 scenarios each)\")\n",
    "print(f\"   Visualization maps: {successful_assessments + 1} files\")\n",
    "\n",
    "# Save final summary\n",
    "summary = {\n",
    "    'processing_date': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'configuration': CONFIG,\n",
    "    'statistics': {\n",
    "        'total_fires': total_fires,\n",
    "        'successful': successful_assessments,\n",
    "        'failed': total_fires - successful_assessments,\n",
    "        'total_area_km2': total_area_km2\n",
    "    },\n",
    "    'outputs': {\n",
    "        'assessment_results': 'assessment_results.json',\n",
    "        'probability_rasters': f\"{CONFIG['paths']['output_folder']}/probability_rasters/\",\n",
    "        'visualizations': f\"{CONFIG['paths']['output_folder']}/visualizations/\"\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('processing_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úÖ COMPLETE WORKFLOW FINISHED!\")\n",
    "print(f\"üìÅ All results saved to: {CONFIG['paths']['output_folder']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f7fdcf",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    " \n",
    "1. **Review Results**: Check the output folders for probability rasters and visualizations\n",
    "2. **Quality Control**: Verify high-risk areas in GIS software\n",
    "3. **Share Products**: Export maps and reports for stakeholders\n",
    "4. **Archive Data**: Backup all processed data and results\n",
    "\n",
    "### Troubleshooting\n",
    " \n",
    "If any fires failed to process:\n",
    "1. Check the error logs in `assessment_results.json`\n",
    "2. Verify input data quality (DEM resolution, soil data completeness)\n",
    "3. Adjust memory optimization settings if needed\n",
    "4. Re-run failed fires individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5799fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample probability raster (if matplotlib available)\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import rasterio\n",
    "    from rasterio.plot import show\n",
    "    \n",
    "    # Find a sample raster\n",
    "    sample_raster = None\n",
    "    raster_folder = os.path.join(CONFIG['paths']['output_folder'], 'probability_rasters')\n",
    "    \n",
    "    if os.path.exists(raster_folder):\n",
    "        for fire_folder in os.listdir(raster_folder):\n",
    "            fire_path = os.path.join(raster_folder, fire_folder)\n",
    "            if os.path.isdir(fire_path):\n",
    "                for raster_file in os.listdir(fire_path):\n",
    "                    if raster_file.endswith('_P_24mmh.tif'):\n",
    "                        sample_raster = os.path.join(fire_path, raster_file)\n",
    "                        break\n",
    "                if sample_raster:\n",
    "                    break\n",
    "    \n",
    "    if sample_raster and os.path.exists(sample_raster):\n",
    "        print(f\"\\nüìä Sample probability raster: {os.path.basename(sample_raster)}\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        with rasterio.open(sample_raster) as src:\n",
    "            show(src, ax=ax, cmap='RdYlBu_r', title='Debris Flow Probability (24mm/hr scenario)')\n",
    "        plt.colorbar(ax.images[0], label='Probability')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\nüìä No sample rasters found for visualization\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"\\nüìä Matplotlib not available for visualization\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nüìä Could not display sample raster: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
